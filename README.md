<h1>Computer Vision (CS 763) - Spring 2019 </h1>

<h2>Course Information</h2>
<ul>
<li><b>Instructor:</b> <a href="http://www.cse.iitb.ac.in/~ajain/">Arjun Jain</a>
<li><b>Office:</b> 216, CSE New Building
<li><b>Email:</b> <i>ajain@cse DOT iitb DOT ac DOT in</i>
<li><b>Teaching Assistants:</b> Rishabh Dabral, Safeer Afaque
<li><b>Class Room:</b> SIC201
<li><b>Instructor Office Hours (in room 216 CSE New Building):</b> TBD
</ul>

<h3> Please note that CS663 is a hard prerequisite for this course.</h3> 

<h2> News and Announcements</h2>
<ul>
<li><b>[8/01/19]</b> Monday class to be moved to 7pm slot to accommodate 3rd year students</li>
<li><b>[14/01/19]</b> The classroom has been moved to <b>SIC201</b> (slots 13A and 15A) due to overflow in CC105</li>
<li><b>[17/01/19]</b> Assignment 1 has been <a href="https://drive.google.com/open?id=1CAlU8fp_46d1tpRcC6evWpkDj1_TAhs4">released</a> and is due by 27th Jan.</li>
<li><b>[30/01/19]</b> Assignment 2 has been <a href="https://drive.google.com/open?id=1JSCprJhTn-46qRDst_AcIV9EDDUeBBif">released</a> and is due by 8th Feb.</li>
<li><b>[10/02/19]</b> Assignment 3 has been <a href="https://drive.google.com/open?id=14LkIcVMAPbO_nemyG6bCsNIOZx7BAfNO">released</a> and is due by 20th Feb.</li>
<li><b>[13/03/19]</b> Assignment 4 has been <a href="https://drive.google.com/open?id=1SV5JSvpz6MAbEShIqDORj8bG8POsbQk2">released</a> and is due by 23rd March.</li>
</ul>	

<h2>Topics to be covered (tentative)</h2>
<ul>
<li> Deep Learning in computer vision: the data-driven paradigm, feed
forwards networks, back-propagation and chain rule; CNNs and their
building blocks, generative adverserial networks (GANs), 
Variational Autoencoders (VAEs) and Conditional Variational 
Autoencoders (CVAEs)
<li> Deep Learning applications including face detection, CNN
compression, siamese and triplet networks and applications to face
recognition
<li> Camera geometry, camera calibration, vanishing points, important
transformations, homographies
<li> Image registration: RANSAC for point-matching, SIFT overview
<li> Algorithms for: shape from shading, optical flow,
Kanade-Lucas-Tomasi algorithm, applications of optical flow
<li> Photometric stereo - deriving shape from multiple images of an
object taken under different lighting conditions; applications to
illumination invariant face recognition, face relighting
<li> Stereo (geometric binocular): epipolar geometry and fundamental
matrix, the correspondence problem and shape from stereo; structure
from motion
</ul>

<h2>Learning materials and textbooks</h2>
<ul>
<li> Lecture slides that will be regularly posted
<li><a href="http://szeliski.org/Book/">Computer Vision: Algorithms and Applications</a>, by Richard Szeliski</li>
<li><a href="http://crcv.ucf.edu/gauss/BOOK.PDF">Fundamentals of Computer Vision</a>, by Mubarak Shah</li>
<li> <a href = "http://www.deeplearningbook.org/">Deep Learning</a>, by Ian Goodfellow and Yoshua Bengio and Aaron Courville 
<li> All <a href="https://github.com/facebook/iTorch">iTorch</a> notebooks for topics covered in class can be found <a href="https://github.com/cs763-dl/2017Spring/tree/master/Notebooks">here</a>
</ul>

<h2>Grading Policy</h2>
<ul>
	<li> Mid-sem exam: 20%
	<li>Final exam (cumulative): 20%
	<li>Assignments (five or six): 35% (all to be done in groups of 2-3 students)
	<li>Course project: 20% (to be done in the same group of 2-3 students)
	<li>Class participation: 5%
	<li>Course project work will be presented by the student group during a viva at the end of the course. During this viva, each student in the group will be separately questioned, not only on the project work, but also the assignments. Each student is expected to contribute to each and every assignment and the course project. 
	<li>Audit requirements: You must write both exams, submit all assignments and the project, and score at least 40% to get an AU.
</ul>

<h2>Other Policies</h2>
<ul>
	<li> Assignments will be given out (typically) once every two or three weeks. They must be submitted on or before the deadline. No late assignments will be accepted. The programming components of the assignments will typically involve MATLAB and lua, so you must be willing to learn it quickly.
	<li><b>We will adopt a zero-tolerance policy against any forms of plagiarism or any other form of cheating. Just don't do it! In cases of plagiarism, givers and takers will both be considered equally responsible.</b>
	<li>This course is (inherently) cumulative. The syllabus for the final exam will include everything taught during the semester.
</ul>

<h2>Course Projects</h2>
As mentioned in the grading policy, this course has a project requirement which will be 20% of your grade. The project needs to be done in a group of 2-3 students. We will send out a form which needs to be filled up with your project proposal. For a list of projects, please check <a href="https://github.com/cs763/Spring2019/tree/master/projects">this link</a>

<h2>Assignments</h2>
There will be 7-8 assignments in this course. They will be a mix of theoretical and programming questions.
<ul>
	<li> Assignment 1 on Camera Geometry has been <a href="https://drive.google.com/open?id=1CAlU8fp_46d1tpRcC6evWpkDj1_TAhs4">released</a> and is due by 27th Jan.
	<li> Assignment 2 on Camera Calibration, Image Alignment and Robust Methods has been <a href="https://drive.google.com/open?id=1JSCprJhTn-46qRDst_AcIV9EDDUeBBif">released</a> and is due by 8th Feb.</li>
	<li> Assignment 3 on Neural Network and Backpropagation has been <a href="https://drive.google.com/open?id=14LkIcVMAPbO_nemyG6bCsNIOZx7BAfNO">released</a> and is due by 20th Feb. Please use <a href="https://www.kaggle.com/t/1ddfc99a4b1a4eb9878a69991b17584c">this</a> Kaggle link to test your predictions and class standing.</li>
	<li> Assignment 4 on Recurrent Neural Network has been <a href="https://drive.google.com/open?id=1SV5JSvpz6MAbEShIqDORj8bG8POsbQk2">released</a> and is due by 23rd March. Please use <a href="https://www.kaggle.com/t/758d87cd34864370ba209bda72f7d29b">this</a> Kaggle link to test your predictions and class standing.</li>
</ul>

<!--ul>
    <li><time datetime="2018-01-12">[12-Jan-18]</time> <a href="https://www.dropbox.com/s/mltmtj7bpc401vm/HW1.pdf?dl=0">Assignment 1</a> has been released. The due date for submission is Friday, January 26, 2018.
    <li><time datetime="2018-01-27">[27-Jan-18]</time> <a href="https://www.dropbox.com/s/u0l7gs0dy2rq11l/HW2.pdf?dl=0">Assignment 2 </a> has been released. The due date for submission is Sunday, February 4, 2018.
    <li><time datetime="2018-02-09">[09-Feb-18]</time> <a href="https://www.dropbox.com/s/b92xpq1zvec5956/HW3.pdf?dl=0">Assignment 3 </a> has been released. The due date for submission is Wednesday, February 21, 2018. <strong>Corresponding kaggle competition <a href="https://www.kaggle.com/c/assign3">link</a></strong>
    <li><time datetime="2018-03-06">[06-Mar-18]</time> <a href="https://www.dropbox.com/s/452ubndyxr9x07l/HW4.pdf?dl=0">Assignment 4 </a> has been released. The due date for submission is Monday, March 19, 2018. <strong>Corresponding kaggle competition <a href="https://www.kaggle.com/t/3b06e8618ccd434293ccbabdfe9598d9">link</a></strong>
<li>[24-March-18] <a href ="https://www.dropbox.com/s/cocjql8bfmytxbh/Assignment_5.pdf?dl=0">Assignment 5</a> on Tracking has been <a href="https://www.dropbox.com/s/cocjql8bfmytxbh/Assignment_5.pdf?dl=0">released</a>. Due date: April 2, 2018. <strong>Download the necessary files from <a href="https://www.dropbox.com/s/z3yzd25vgw5cma0/HW5.tar.gz?dl=0">here</a></strong>
<li>[11-April-18] Assignment 6 on Multiview Geometry has been <a href="https://www.dropbox.com/s/ox41nidn99qw56r/Assignment_6.pdf?dl=0">released</a>. Due date: April 19, 2018.
</ul-->

<h2>Lecture Schedule: </h2>

<table>
  <tbody>  
    <tr>
      <th>Date</th>
      <th>Topics</th>
      <th>Slides</th>
      <th>iTorch Notebooks</th>
      <th>Extra Reading</th>
    </tr>  	  
    <tr>
      <td>7th Jan, 2019</td>
      <td><ul><li>Introduction to computer vision, applications and course overview <ul></td>
      <td><a href="https://drive.google.com/open?id=1i4lFRBwYeed8dHE_c2p4pnMF2k60OW8G">Slides</a></td>
      <td align="center"> --
      </td>
      <td align="center">--</td>
    </tr>        
    <tr>
      <td>8th Jan, 2019</td>
      <td>
	<strong>Camera Geometry</strong>
	<ul>
	<li>Homogeneous coordinates and projective geometry
        <li>Vanishing points, ideal line, point line duality in P2  
	<li>Introduction to the pin-hole camera model
      </ul></td>
      <td><a href="https://drive.google.com/open?id=1dlewCNVqshBiPP6v3OvI8Rk4uds4L1U8">Slides</a></td>
      <td align="center"> --
      </td>
      <td><a href="http://www.ipb.uni-bonn.de/book-pcv/pdfs/PCV-A-sample-page.pdf">Homogeneous Representations of Points, Lines and Planes</a></td>
    </tr>
    <tr>
      <td>14th Jan, 2019</td>
      <td>
	<ul>
	<li>Important 2D and 3D transformations using homogenous coordinates
	<li>Modeling the pinhole camera analytically, intinsic and extrinsic parameters
	<li>World, camera, image plane and sensor plane coordinate systems and transformations between them
      </ul></td>
      <td><a href="https://drive.google.com/open?id=161WR4nVHlMm6WMc7DJoc-9NuAONPETfB">Slides</a></td>
      <td align="center"> --
      </td>
      <td align="center"> -- </td>
    </tr>
    <tr>
      <td>15th Jan, 2019</td>
      <td>
	<ul>
	<li>Linear and non-linear (lens distortion) errors
	<li>Homography, planar world and pure rotation of the camera
	<li>Iterative solutions for dealing with with non-linear (lens distortion) errors
	<li>Normalized,  ideal, euclidian, affine and general camera models
	<li>Orthographic and weak-perspective camera models
      </ul></td>
      <td><a href="https://drive.google.com/open?id=1E7YgsBX2eD8GAOc7-5EJe-ssIgBw_crX">Slides</a></td>
      <td align="center"> --
      </td>
      <td align="center"> -- </td>
    </tr>
    <tr>
      <td>21st Jan, 2019</td>
      <td>
	<ul>
	<li>Cross ratios and its applications
	<li>Camera calibration using DLT (known 3D control points)
	<li>Introduction to Zhang's camera calibration method
        </ul>
      </td>
      <td><a href="https://drive.google.com/open?id=1ENsJKX9XDOQG9GJ9pAAHyngxxUnfiGL1">Slides</a></td>
      </td>
      <td align="center"> -- </td>
      <td>
	<a href="http://inside.mines.edu/~whoff/courses/EENG512/lectures/17-SVD.pdf">Resource on SVD</a><br/>
	Additional <a href="http://cmp.felk.cvut.cz/cmp/courses/XE33PVR/WS20072008/Lectures/Supporting/constrained_lsq.pdf">slides</a> and <a href="https://foto.aalto.fi/seura/julkaisut/pjf/pjf_e/2005/Inkila_2005_PJF.pdf">notes</a> on solving homogenous least squares problem</a><br/>
    </tr>
    <tr>
      <td>22nd Jan, 2019</td>
      <td>
	<ul>
	<li>Zhang's camera calibration method, mention of a few DL based calibration methods
	</ul>
	      <strong>Image Alignment</strong>
	<ul>
	<li>Image alignment: problem statement, physically and digitally corresponding points
	<li> Motion models and degrees of freedom; non-rigid/deformable/non-parametric image alignment
	<li> Control point based image alignment using least squares - derivation for pseudo-inverse
	<li> Introduction to the SIFT algorithm
	<li> Forward and reverse image warping - bilinear and nearest-neighbor interpolation
	<li> Mention of DL based image patch descriptors
      </ul></td>
      <td><a href="https://drive.google.com/open?id=1W9sQn-O1IUYrHJFf1lsbQYtxOxVWIJGp">Slides</a></td>
      <td align="center"> --
      </td>
      <td align="center"> -- </td>
    </tr>
    <tr>
      <td>28th Jan, 2019</td>
      <td>
	<ul>
	<li>Image alignment using image similarity measures: mean squared error, normalized cross-correlation
	<li>Concept of field of view in image alignment using image similarity measures
	<li>Monomodal and multimodal image alignment
	<li>Concept of joint histograms and behaviour of joint histograms in multi-modal image alignment	
	<li>Concept of entropy and joint entropy, algorithm for multimodal registration by minimizing joint entropy
	<li>Aspects of image registration: 2D/3D, motion model, monomodal or multimodal
	<li>Application scenarios for image alignment: template matching, video stabilization, panorama generation, face recognition, 3D to 2D alignment
      </ul></td>
      <td><a href="https://drive.google.com/open?id=1lfIsf5ajCPElAgOzCekcQJ1KA-Me4LVG">Slides</a></td>
      <td align="center"> --
      </td>
      <td align="center"> -- </td>
    </tr>
    <tr>
      <td>29th Jan, 2019</td>
      <td>
	<strong>Robust Methods in Computer Vision</strong>
	<ul>
	<li>Least squares problems and their relation to the Gaussian distribution on the noise
	<li>Examples of outliers in computer vision
	<li>Explanation of why the Gaussian distribution is unsuited to handling outliers
	<li>Introduction to the Laplacian distribution
	<li>The importance of heavy-tailed distributions in robust statistics
	<li>RANSAC (random sample consensus) algorithm
      </ul></td>
      <td><a href="https://drive.google.com/open?id=1RqxMvSm30aOOR36RLL1GFw8zOobyPLNk">Slides</a></td>
      <td align="center"> --
      </td>
      <td align="center"> -- </td>
    </tr>
    <tr>
      <td>4th Feb, 2019</td>
      <td>
	<strong>Deep Learning for Computer Vision</strong>
	<ul>
	<li>History, introduction
	<li>Data driven paradigm
	<li>K-NN on CIFAR 10
	<li>Hyperparameters, choice of loss function, cross-validation
	<li>Softmax classifier, cross-entropy loss function, regularization
	<li>Optimization: vanilla gradient descent, stochastic gradient descent
      </ul></td>
      <td><a href="https://drive.google.com/open?id=1xwrD6q_f0vimHesxKYLBIqNEgnr6De6O">Slides</a></td>
      <td align="center">  <a href="https://github.com/cs763/Spring2018/blob/master/notebooks/NN.ipynb">KNN</a>
      </td>
      <td align="center"><a href="http://parrt.cs.usfca.edu/doc/matrix-calculus/index.html">Matrix calculus reminder</a> </td>
    </tr>
    <tr>
      <td>5th Feb, 2019</td>
      <td>
	<ul>
	<li>Vanilla momentum, Nesterov momentum, AdaGrad, RMSProp, ADAM 
	<li>Second order optimization methods, it's issues with deep learning
	<li>Good learning rate, learning rate decay
	<li>Feed forward, back-propagation
	<li>Fully connected layer
      </ul></td>
      <td><a href="https://drive.google.com/open?id=1qAIGlBDzlqK7hJ5yq94n7SS5gMXgCwoM">Slides</a></td>
      <td align="center"> <a href="https://www.dropbox.com/s/i3jvya22tf5jtbs/GradientCheck.ipynb?dl=0">Gradient Check</a>,
			<a href="https://github.com/cs763/Spring2018/blob/master/notebooks/Linear.ipynb">Linear Layer</a></td>
      <td > <a href="https://github.com/pytorch/pytorch/blob/master/torch/optim/adam.py#L58">ADAM</a>, 
     	    <a href="https://github.com/fidlej/optim/raw/master/dok/nesterov_simple.pdf">Nesterov</a> <br/>
            <a href="http://ruder.io/optimizing-gradient-descent/index.html">DL optimization algorithms overview</a>
      </td>
    </tr>
    <tr>
      <td>11th Feb, 2019</td>
      <td>
	<ul>
	<li>Activation functions: sigmoid, tanh, ReLU, LeakyReLU, ELU, etc.
	<li>Convolutional layer, dilated convolutions.
      </ul></td>
      <td><a href="https://drive.google.com/open?id=1MePXPGCV8lVP4GMryKpoLJC8rgij_YiJ">Slides</a></td>
      <td align="center"> <a href="https://github.com/cs763/Spring2018/blob/master/notebooks/Convolution.ipynb">Convolution</a></td>
      <td > <a href="https://arxiv.org/pdf/1603.07285.pdf">Convolution arithmetic for deep
learning</a> </a>
      </td>
    </tr>
    <tr>
      <td>12th Feb, 2019</td>
      <td>
	<ul>
	<li>Convolutions: transposed, dilated, fully-connected as convolution, sliding window as convolution
	<li>Max-pooling, Dropout
	<li>SoftMax, Cross Entropy
      </ul></td>
      <td><a href="https://drive.google.com/open?id=1HSbACNNUrWUG3wihOt8JNSps845YBXXl">Slides</a></td>
      <td align="center"> <a href="https://github.com/cs763/Spring2018/blob/master/notebooks/Transposed%20Convolution.ipynb">Transposed convolution</a>, <a href="https://github.com/cs763/Spring2018/blob/master/notebooks/Max-Pool.ipynb">MaxPool</a>, <a href="https://github.com/cs763/Spring2018/blob/master/notebooks/CEC.ipynb">Cross Entropy</a></td>
      <td align="center"> -- </a>
      </td>
    </tr>
    <tr>
      <td>18th Feb, 2019</td>
      <td>
	<ul>
	<li>Data Augmentation, hyperparamter selection
	<li>Weight initialization
	<li>Babysitting the learning process
      </ul></td>
      <td><a href="https://drive.google.com/open?id=1hI028G8kDopJJSINNxm-miHNV4ENGEz2">Slides</a></td>
      <td align="center"> <a href="https://github.com/cs763/Spring2018/blob/master/notebooks/WeightInit.ipynb">Weight Initialization</a></td>
      <td align="center"> -- </a>
      </td>
    </tr>
    <tr>
      <td>19th Feb, 2019</td>
      <td>
	<ul>
	<li>ConvNet applications
	<li>ConvNet case studies: AlexNet, ZF-Net, VGGNet, GoogleNet, ResNet, SE-Net
	<li>Transfer Learning
      </ul></td>
      <td><a href="https://drive.google.com/open?id=1AQ1k6e9p0DtPizGERbm4WQseoNE687u3">Slides</a></td>
      <td align="center"> -- </td>
      <td align="center"> -- </a>
      </td>
    </tr>
    <tr>
      <td>4th March, 2019</td>
      <td>
	<ul>
	<li>Object Detection: RCNN, Fast-RCNN, Faster-RCNN, YOLO, SSD
      </ul></td>
      <td><a href="https://drive.google.com/open?id=1EMq1D76jUmLmsGMHCmZbdUh_iojxlq1m">Slides</a></td>
      <td align="center"> -- </td>
      <td align="center"> -- </a>
      </td>
    </tr>
    <tr>
      <td>5th March, 2019</td>
      <td>
	<ul>
	<li>Object Detection evaluation metrics: IoU, mAP
	<li>Object Detection details: RoIAlign, Feature Pyramid Network, Mask-RCNN, Focal Loss	
      </ul></td>
      <td><a href="https://drive.google.com/open?id=1EMq1D76jUmLmsGMHCmZbdUh_iojxlq1m">Slides</a></td>
      <td align="center"> -- </td>
      <td align="center"> -- </a>
      </td>
    </tr>
    <tr>
      <td>11th March, 2019</td>
      <td>
	<ul>
	<li>RNNs, LSTMs
      </ul></td>
      <td><a href="https://drive.google.com/open?id=10Di1sNnBe8DkyZ0fwwKRPPvCjcA89prU">Slides</a></td>
      <td align="center"> -- </td>
      <td align="center"> -- </a>
      </td>
    </tr>
    <tr>
      <td>12th March, 2019</td>
      <td>
	<ul>
	<li>Visualizing and understanding ConvNets
	<li>Images that maximize ConvNet class scores, reconstructing images from ConvNet <i>codes</i>
	<li>Deep Dream, Neural Art, Adversarial Examples
	<li>Dimentionality reduction: siamese and triplet networks
      </ul></td>
      <td><a href="https://drive.google.com/open?id=1fBsYmJ_CQysMQusggoXcsxUsEbn5b3Kr">Slides</a></td>
      <td align="center"> -- </td>
      <td align="center"> -- </a>
      </td>
    </tr>
    <tr>
      <td>18th March, 2019</td>
      <td>
	<ul>
	<li>Neural Style Transfer
	<li>Autoencoders
	<li>Generative modeling: VAEs, GANs
	<li>Case studies: pix2pix, CycleGAN, UNIT
      </ul></td>
      <td><a href="https://drive.google.com/open?id=1sHQT2mn6E9yKcSSHXUJZH5Dw0qgaW5id">Slides 1</a>
	  <a href="https://drive.google.com/open?id=1oK7GwAY7oHYV32LUgxyEJoJZ3Zrqfl0d">Slides 2</td>
      <td align="center"> -- </td>
      <td align="center"> -- </a>
      </td>
    </tr>
    <tr>
      <td>26th March, 2019</td>
      <td>
	<ul>
		<li> <strong>Orthographic Structure from Motion</strong>
      </ul></td>
      <td><a href="https://drive.google.com/open?id=1m8sz3hF_qYQ6AoCqWOxq3yWyHHSBQzST">Slides</a></td>
      <td align="center"> -- </td>
      <td align="center"> -- </a>
      </td>
    </tr>
    <tr>
      <td>1st April, 2019</td>
      <td>
	      <strong> Optical Flow </strong>
      <ul>
		<li> Dealing with the aperture problem: regularization
	        <li> Horn and Shunck method: algorithm using discrete formulation, steps of Jacobi's method for matrix inversion, and comments about limitations 
      </ul></td>
      <td><a href="https://www.cse.iitb.ac.in/~ajitvr/CS763_Spring2017//OpticalFlow.pdf">Slides</a></td>
      <td align="center"> -- </td>
      <td align="center"> -- </a> </td>
    </tr>
    <tr>
      <td>2nd April, 2019</td>
      <td>
      <ul>
		<li> Lucas-Kanade method for Optical Flow
		<li> Multi-Scale Lucas-Kanade method
		<li> Comparison of Horn-Shunk and Lucas-Kanade algorithms
		<li> Applications of Optical Flow
      </ul></td>
      <td><a href="https://www.cse.iitb.ac.in/~ajitvr/CS763_Spring2017//OpticalFlow.pdf">Slides</a></td>
      <td align="center"> -- </td>
      <td align="center"> -- </a>
      </td>
    </tr>
    <tr>
      <td>8th April, 2019</td>
      <td>
	<strong>Kanade-Lucas-Tomasi (KLT) Featurepoint Tracker</strong>
	<ul>		
        <li>Tracking feature-points from a template by estimating motion parameters.
	<li>Finding good features to track.
      </ul></td>
      </ul></td>
      <td><a href="https://drive.google.com/open?id=18oO-sIeJmfLTQTtE9rc7U8Ck8E30U6-x">Slides</a></td>
      <td align="center"> -- </td>
      <td align="<a href="http://www.ncorr.com/download/publications/bakerunify.pdf">Lucas-Kanade 20 Years On: A Unifying Framework</a><br/>
      </td>
    </tr>
</tbody>
</table>



